{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "parFile = '/nfs/attic/dfh/Aragon2/mar2020_snowmodel-dfhill/snowmodel.par'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['60', 'nx - grid cells in east/west direction\\n', 0]\n"
     ]
    }
   ],
   "source": [
    "#create dictionay with values from text file - may want to use for calibration\n",
    "def getparams(file_name):\n",
    "    myvars = {}\n",
    "    lines = open(file_name, 'r').readlines()\n",
    "    for i in range(len(lines)):\n",
    "        line=lines[i]\n",
    "        if i == 14 or i == 17 or i == 18 or i == 19 or i == 93 or i == 95 \\\n",
    "        or i == 97 or i == 100 or i == 102 or i == 104 or i == 107 or i == 108:\n",
    "            var = line.strip()\n",
    "            if i == 14:\n",
    "                name = 'met_input_fname'\n",
    "            elif i == 17:\n",
    "                name = 'topoveg_grads_fname'\n",
    "            elif i == 18:\n",
    "                name = 'topo_ascii_fname'\n",
    "            elif i == 19:\n",
    "                name = 'veg_ascii_fname'\n",
    "            elif i == 93:\n",
    "                name = 'micromet_output_fname'\n",
    "            elif i == 95:\n",
    "                name = 'snowtran_output_fname'\n",
    "            elif i == 97:\n",
    "                name = 'tabler_sfc_path_name'\n",
    "            elif i == 100:\n",
    "                name = 'enbal_output_fname'\n",
    "            elif i == 102:\n",
    "                name = 'snowpack_output_fname'\n",
    "            elif i == 104:\n",
    "                name = 'multilayer_output_fname'\n",
    "            elif i == 107:\n",
    "                name = 'output_path_wo_assim'\n",
    "            elif i == 108:\n",
    "                name = 'output_path_wi_assim'\n",
    "            myvars[name] = [var,name,i]\n",
    "        else:\n",
    "            var, name = line.partition(\"!\")[::2]\n",
    "            #create a dictionary with the variable name as the key for the \n",
    "            #[model value, parFile text, linenumber]\n",
    "            myvars[name.split()[0]] = [var.strip(),name,i]\n",
    "    return myvars\n",
    "base = getparams(parFile)\n",
    "#print(base)\n",
    "print(base['nx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nx\n",
      "['60', 'nx - grid cells in east/west direction\\n', 0]\n",
      "ny\n",
      "['41', 'ny - grid cells in north/south direction\\n', 1]\n",
      "deltax\n",
      "['100', 'deltax - grid spacing in e/w (m)\\n', 2]\n",
      "deltay\n",
      "['100', 'deltay - grid spacing in n/s (m)\\n', 3]\n",
      "xmn\n",
      "['423150.00', 'xmn - x location of lower left grid cell center (m)\\n', 4]\n",
      "ymn\n",
      "['4409250.00', 'ymn - y location of lower left grid cell center (m)\\n', 5]\n",
      "dt\n",
      "['10800', 'dt - model time step (s)\\n', 6]\n",
      "iyear_init\n",
      "['2017', 'iyear_init - start year\\n', 7]\n",
      "imonth_init\n",
      "['9', 'imonth_init - start month\\n', 8]\n",
      "iday_init\n",
      "['1', 'iday_init - start day\\n', 9]\n",
      "xhour_init\n",
      "['3.0', 'xhour_init - start hour\\n', 10]\n",
      "max_iter\n",
      "['2920', 'max_iter - number of model time steps\\n', 11]\n",
      "isingle_stn_flag\n",
      "['0', 'isingle_stn_flag (set to 0 for multi-station met input)\\n', 12]\n",
      "igrads_metfile\n",
      "['0', 'igrads_metfile (set to 0 for multi-station met input)\\n', 13]\n",
      "met_input_fname\n",
      "['met/nldas2/7_mk_mm/mm_3hrly_2017-2018.dat', 'met_input_fname', 14]\n",
      "undef\n",
      "['-9999', 'undef - undefined data flag in both inputs and outputs\\n', 15]\n",
      "ascii_topoveg\n",
      "['0.0', 'ascii_topoveg - 1 for esri/ascii topo/veg files; 0 for GRADS\\n', 16]\n",
      "topoveg_grads_fname\n",
      "['topo_vege/NoAm_30m/topo_vege.gdat', 'topoveg_grads_fname', 17]\n",
      "topo_ascii_fname\n",
      "['xxxxxx', 'topo_ascii_fname', 18]\n",
      "veg_ascii_fname\n",
      "['xxxxxx', 'veg_ascii_fname', 19]\n",
      "ved_shd_25\n",
      "['0.1', 'ved_shd_25 - snow holding depth (m) for veg class 25\\n', 20]\n",
      "ved_shd_26\n",
      "['0.1', 'ved_shd_26 - snow holding depth (m) for veg class 26\\n', 21]\n",
      "ved_shd_27\n",
      "['0.1', 'ved_shd_27 - snow holding depth (m) for veg class 27\\n', 22]\n",
      "ved_shd_28\n",
      "['0.1', 'ved_shd_28 - snow holding depth (m) for veg class 28\\n', 23]\n",
      "ved_shd_29\n",
      "['0.1', 'ved_shd_29 - snow holding depth (m) for veg class 29\\n', 24]\n",
      "ved_shd_30\n",
      "['0.1', 'ved_shd_30 - snow holding depth (m) for veg class 30\\n', 25]\n",
      "const_veg_flag\n",
      "['0.0', 'const_veg_flag - 0 if using veg file; otherwise a veg class (e.g. 12)\\n', 26]\n",
      "iveg_ht_flag\n",
      "['0', 'iveg_ht_flag - 0 to not use veg height; -1 for grads, 1 for ascii\\n', 27]\n",
      "xlat\n",
      "['39.85', 'xlat - mean lat of your domain (for solar calculations)\\n', 28]\n",
      "lat_solar_flag\n",
      "['0', 'lat_solar_flag - 0 for small domain, 1 for ascii, -1 for grads\\n', 29]\n",
      "UTC_flag\n",
      "['0.0', 'UTC_flag - 0 for small domain, 1 for ascii, -1 for grads\\n', 30]\n",
      "run_micromet\n",
      "['1.0', 'run_micromet - 1 for yes\\n', 31]\n",
      "run_enbal\n",
      "['1.0', 'run_enbal - 1 for yes\\n', 32]\n",
      "run_snowpack\n",
      "['1.0', 'run_snowpack - 1 for yes\\n', 33]\n",
      "run_snowtran\n",
      "['1.0', 'run_snowtran - 1 for yes\\n', 34]\n",
      "irun_data_assim\n",
      "['0', 'irun_data_assim - 0 for straight run; 1 for assim run\\n', 35]\n",
      "ihrestart_flag\n",
      "['-2', 'ihrestart_flag - -2 for no restart\\n', 36]\n",
      "i_dataassim_loop\n",
      "['1', 'i_dataassim_loop - 1 for straight run\\n', 37]\n",
      "ihrestart_inc\n",
      "['0', 'ihrestart_inc - 0 if no restarting; this is the restart increment\\n', 38]\n",
      "i_tair_flag\n",
      "['1', 'i_tair_flag - 1 if you wish micromet to distribute temp\\n', 39]\n",
      "i_rh_flag\n",
      "['1', 'i_rh_flag - 1 if you wish micromet to distribute rel hum\\n', 40]\n",
      "i_wind_flag\n",
      "['1', 'i_wind_flag - 1 if you wish micromet to distribute wind\\n', 41]\n",
      "i_solar_flag\n",
      "['1', 'i_solar_flag - 1 if you wish micromet to distribute SWR\\n', 42]\n",
      "i_longwave_flag\n",
      "['1', 'i_longwave_flag - 1 if you wish micromet to distribute LWR\\n', 43]\n",
      "i_prec_flag\n",
      "['1', 'i_prec_flag - 1 if you wish micromet to distribute precip\\n', 44]\n",
      "ifill\n",
      "['1', 'ifill - 1 to calculate values for all grid cells\\n', 45]\n",
      "iobsint\n",
      "['0', 'iobsint - 0 to let model decide; 1 for user specified\\n', 46]\n",
      "dn\n",
      "['1.0', 'dn - units of deltax/y; radius of influence for interpolation\\n', 47]\n",
      "barnes_lg_domain\n",
      "['1.0', 'barnes_lg_domain - 0 to use all stations; 1 for local only\\n', 48]\n",
      "n_stns_used\n",
      "['4', 'n_stns_used - number of neighbors for interpolation\\n', 49]\n",
      "snowmodel_line_flag\n",
      "['0.0', 'snowmodel_line_flag - 0 to run whole domain, 1 for limited cells\\n', 50]\n",
      "check_met_data\n",
      "['1.0', 'check_met_data - 1 will check for valid data; not wise for long, large runs\\n', 51]\n",
      "curve_len_scale\n",
      "['300.0', 'curve_len_scale (m); set to ~1/2 the wavelength of topo features in domain\\n', 52]\n",
      "slopewt\n",
      "['0.58', 'slopewt - sum of this and curvewt should be 1; weighting factors\\n', 53]\n",
      "curvewt\n",
      "['0.42', 'curvewt\\n', 54]\n",
      "curve_lg_scale_flag\n",
      "['0.0', 'curve_lg_scale_flag\\n', 55]\n",
      "windspd_min\n",
      "['0.1', 'windspd_min - min wind speed (avoid blowing up when wind-->0.\\n', 56]\n",
      "lapse_rate_user_flag\n",
      "['0', 'lapse_rate_user_flag - 0 for default; 1 for user specified.\\n', 57]\n",
      "iprecip_lapse_rate_user_flag\n",
      "['0', 'iprecip_lapse_rate_user_flag - same as above\\n', 58]\n",
      "iprecip_scheme\n",
      "['1', 'iprecip_scheme - 1 for original scheme\\n', 59]\n",
      "snowfall_frac\n",
      "['3.0', 'snowfall_frac - 1 for Auer, 2 for Dai, 3 for Liston\\n', 60]\n",
      "wind_lapse_rate\n",
      "['0.0', 'wind_lapse_rate - multiplier for increasing wind speeds\\n', 61]\n",
      "calc_subcanopy_met\n",
      "['1.0', 'calc_subcanopy_met - 1 for sub canopy values; 0 for above canopy\\n', 62]\n",
      "gap_frac\n",
      "['0.2', 'gap_frac - canopy gap fraction\\n', 63]\n",
      "cloud_frac_factor\n",
      "['1.0', 'cloud_frac_factor - 1 for normal, lower to decrease cloud fraction\\n', 64]\n",
      "use_shortwave_obs\n",
      "['0.0', 'use_shortwave_obs - 0 for model computed radiation, 1 for data\\n', 65]\n",
      "use_longwave_obs\n",
      "['0.0', 'use_longwave_obs - 0 for model computed radiation, 1 for data\\n', 66]\n",
      "use_sfc_pressure_obs\n",
      "['0.0', 'use_sfc_pressure_obs - 1 to use data file for pressure\\n', 67]\n",
      "cf_precip_flag\n",
      "['0.0', 'cf_precip_flag - 0 for none, 1 for 2d grads, 2 for 2d text, 3 for scalar\\n', 68]\n",
      "Utau_t_flag\n",
      "['0.0', 'Utau_t_flag - constant (0) or variable (1) surface shear velocity\\n', 69]\n",
      "Utau_t_const\n",
      "['0.25', 'Utau_t_const - threshold surface shear velocity if Utau_t_flag = 0\\n', 70]\n",
      "subgrid_flag\n",
      "['0.0', 'subgrid_flag - 0 for res > 30 m, 1 for res < 30 m\\n', 71]\n",
      "tabler_dir\n",
      "['-270.0', 'tabler_dir - dominant wind dir if subgrid_flag = 1\\n', 72]\n",
      "slope_adjust\n",
      "['1.0', 'slope_adjust - adjusts slope of Tabler surfaces\\n', 73]\n",
      "twolayer_flag\n",
      "['1.0', 'twolayer_flag - 1 for two-layer accounting of soft and hard layers\\n', 74]\n",
      "bc_flag\n",
      "['0.0', 'bc_flag - 0 for zero flux at upwind boundaries, 1 for eq. flux\\n', 75]\n",
      "ht_windobs\n",
      "['10.0', 'ht_windobs - in (m)\\n', 76]\n",
      "ht_rhobs\n",
      "['10.0', 'ht_rhobs - in (m)\\n', 77]\n",
      "ro_snow\n",
      "['300.0', 'ro_snow - snow density for snow-tran 3d.\\n', 78]\n",
      "snow_d_init_const\n",
      "['0.0', 'snow_d_init_const - initial snow depth\\n', 79]\n",
      "topoflag\n",
      "['1.0', 'topoflag - 1 to use surface topo equal to snow topo; 0 for ground topo\\n', 80]\n",
      "icond_flag\n",
      "['0', 'icond_flag - 0 for no conduction; 1 for conduction\\n', 81]\n",
      "albedo_snow_forest\n",
      "['0.45', 'albedo_snow_forest - albedo under forest canopy for melting snowcover\\n', 82]\n",
      "albedo_snow_clearing\n",
      "['0.6', 'albedo_snow_clearing - albedo for melting snow in non-forested areas\\n', 83]\n",
      "albedo_glacier\n",
      "['0.4', 'albedo_glacier - albedo for glacier surface\\n', 84]\n",
      "sfc_sublim_flag\n",
      "['1.0', 'sfc_sublim_flag - 1 for static-surface sublimation\\n', 85]\n",
      "multilayer_snowpack\n",
      "['0', 'multilayer_snowpack - 1 for yes; 0 for no. Must be off off for assim runs\\n', 86]\n",
      "tsls_threshold\n",
      "['24.0', 'tsls_threshold - time since last snowfall threshold\\n', 87]\n",
      "max_layers\n",
      "['1', 'max_layers - max layers allowed in a multi-layer run\\n', 88]\n",
      "dz_snow_min\n",
      "['0.001', 'dz_snow_min  - min snow layer thickness for a multi layer run\\n', 89]\n",
      "izero_snow_date\n",
      "['090100', 'izero_snow_date - date to zero out snowpack in multi year run\\n', 90]\n",
      "seaice_run\n",
      "['0.0', 'seaice_run - 0 for land only run. See doc for other options\\n', 91]\n",
      "print_micromet\n",
      "['0.0', 'print_micromet - 1 to write it out; 0 to not\\n', 92]\n",
      "micromet_output_fname\n",
      "['outputs/micromet.gdat', 'micromet_output_fname', 93]\n",
      "print_snowtran\n",
      "['0.0', 'print_snowtran - 1 to write it out; 0 to not\\n', 94]\n",
      "snowtran_output_fname\n",
      "['outputs/snowtran.gdat', 'snowtran_output_fname', 95]\n",
      "Tabler_1_flag\n",
      "['0.0', 'Tabler_1_flag - 0 to not write out\\n', 96]\n",
      "tabler_sfc_path_name\n",
      "['outputs/', 'tabler_sfc_path_name', 97]\n",
      "Tabler_2_flag\n",
      "['0.0', 'Tabler_2_flag - 0 to not write out\\n', 98]\n",
      "print_enbal\n",
      "['0.0', 'print_enbal - 0 to not write out\\n', 99]\n",
      "enbal_output_fname\n",
      "['outputs/enbal.gdat', 'enbal_output_fname', 100]\n",
      "print_snowpack\n",
      "['0.0', 'print_snowpack - 0 to not write out\\n', 101]\n",
      "snowpack_output_fname\n",
      "['outputs/snowpack.gdat', 'snowpack_output_fname', 102]\n",
      "print_multilayer\n",
      "['0.0', 'print_multilayer - 0 to not write out\\n', 103]\n",
      "multilayer_output_fname\n",
      "['outputs/multilayer.gdat', 'multilayer_output_fname', 104]\n",
      "print_user\n",
      "['1.0', 'print_user - 1 to print stuff out; 0 to not\\n', 105]\n",
      "print_inc\n",
      "['8.0', 'print_inc - increment of time steps for output (3 hr time step x 8 = daily)\\n', 106]\n",
      "output_path_wo_assim\n",
      "['outputs/wo_assim/', 'output_path_wo_assim', 107]\n",
      "output_path_wi_assim\n",
      "['outputs/wi_assim/', 'output_path_wi_assim', 108]\n",
      "print_var_01\n",
      "['n', 'print_var_01 - air temp (degC) (y to print; n to not)\\n', 109]\n",
      "print_var_02\n",
      "['n', 'print_var_02 - relative humidity (%) (y to print; n to not)\\n', 110]\n",
      "print_var_03\n",
      "['n', 'print_var_03 - wind speed (m/s) (y to print; n to not)\\n', 111]\n",
      "print_var_04\n",
      "['n', 'print_var_04 - incoming solar rad (W/m2) (y to print; n to not)\\n', 112]\n",
      "print_var_05\n",
      "['n', 'print_var_05 - incoming longwave rad (W/m2) (y to print; n to not)\\n', 113]\n",
      "print_var_06\n",
      "['n', 'print_var_06 - outgoing longwave (W/m2) (y to print; n to not)\\n', 114]\n",
      "print_var_07\n",
      "['n', 'print_var_07 - albedo (0-1) (y to print; n to not)\\n', 115]\n",
      "print_var_08\n",
      "['n', 'print_var_08 - wind dir (0-360) (y to print; n to not)\\n', 116]\n",
      "print_var_09\n",
      "['n', 'print_var_09 - w.eq. precip (m / time step) (y to print; n to not)\\n', 117]\n",
      "print_var_10\n",
      "['n', 'print_var_10 - liquid precip (m / time step) (y to print; n to not)\\n', 118]\n",
      "print_var_11\n",
      "['n', 'print_var_11 - solid precip (m / time step) (y to print; n to not)\\n', 119]\n",
      "print_var_12\n",
      "['n', 'print_var_12 - SWE melt (m) (y to print; n to not)\\n', 120]\n",
      "print_var_13\n",
      "['n', 'print_var_13 - static surface subl (m) (y to print; n to not)\\n', 121]\n",
      "print_var_14\n",
      "['n', 'print_var_14 - runoff from base of snowpack (m / time step) (y to print; n to not)\\n', 122]\n",
      "print_var_15\n",
      "['n', 'print_var_15 - swe melt from glacier ice (m) (y to print; n to not)\\n', 123]\n",
      "print_var_16\n",
      "['n', 'print_var_16 - snow depth (m) (y to print; n to not)\\n', 124]\n",
      "print_var_17\n",
      "['n', 'print_var_17 - snow density (kg/m3) (y to print; n to not)\\n', 125]\n",
      "print_var_18\n",
      "['y', 'print_var_18 - swe (m) (y to print; n to not)\\n', 126]\n",
      "print_var_19\n",
      "['n', 'print_var_19 - summed snow precip during year (m) (y to print; n to not)\\n', 127]\n",
      "print_var_20\n",
      "['n', 'print_var_20 - summed swe melt during year (m) (y to print; n to not)\\n', 128]\n",
      "print_var_21\n",
      "['n', 'print_var_21 - cloud fraction (0-1) (y to print; n to not)\\n', 129]\n",
      "print_var_22\n",
      "['n', 'print_var_22 - user defined (y to print; n to not)\\n', 130]\n",
      "print_var_23\n",
      "['n', 'print_var_23 - user defined (y to print; n to not)\\n', 131]\n",
      "print_var_24\n",
      "['n', 'print_var_24 - user defined (y to print; n to not)\\n', 132]\n",
      "print_var_25\n",
      "['n', 'print_var_25 - user defined (y to print; n to not)\\n', 133]\n",
      "print_var_26\n",
      "['n', 'print_var_26 - user defined (y to print; n to not)\\n', 134]\n",
      "print_var_27\n",
      "['n', 'print_var_27 - user defined (y to print; n to not)\\n', 135]\n",
      "print_var_28\n",
      "['n', 'print_var_28 - user defined (y to print; n to not)\\n', 136]\n",
      "print_var_29\n",
      "['n', 'print_var_29 - user defined (y to print; n to not)\\n', 137]\n",
      "print_var_30\n",
      "['n', 'print_var_30 - user defined (y to print; n to not)\\n', 138]\n",
      "ro_snowmax\n",
      "['550.0', 'ro_snowmax - maximum snow density (model default = 550.0)\\n', 139]\n",
      "ro_adjust\n",
      "['5.0', 'ro_adjust - density adjustment factor (default is 5)\\n', 140]\n",
      "cf_precip_scalar\n",
      "['1.0', 'cf_precip_scalar -  constant precip factor (when cf_precip__flag=3)\\n', 141]\n",
      "T_threshold\n",
      "['2.0', 'T_threshold - rain / snow threshold, a la Auer. (recommend 2.0)\\n', 142]\n",
      "T_Left,\n",
      "['-.5667,2.7667', 'T_Left, T_Right - bounding values for linear ramp for rain/snow\\n', 143]\n",
      "lapse_rate\n",
      "['4.4,5.9,7.1,7.8,8.1,8.2,8.1,8.1,7.7,6.8,5.5,4.7', 'lapse_rate - temp lapse rate\\n', 144]\n",
      "am\n",
      "['0.41,0.42,0.40,0.39,0.38,0.36,0.33,0.33,0.36,0.37,0.40,0.40', 'am (vapor press coeff)\\n', 145]\n",
      "prec_lapse_rate\n",
      "['0.35,0.35,0.35,0.30,0.25,0.20, 0.20,0.20,0.20,0.25,0.30,0.35', 'prec_lapse_rate (1/km)\\n', 146]\n"
     ]
    }
   ],
   "source": [
    "for key in base:\n",
    "    print(key)\n",
    "    print(base[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save baseline .par file\n",
    "import json\n",
    "\n",
    "json = json.dumps(base)\n",
    "f = open(\"par_base.json\",\"w\")\n",
    "f.write(json)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#likely a way to do this with a dictionary \n",
    "def edit_par(par_dict,parameter,new_value):\n",
    "    lines = open(parFile, 'r').readlines()\n",
    "    text = str(new_value)+'\\t\\t\\t!'+par_dict[parameter][1]\n",
    "    lines[par_dict[parameter][2]-1] = text\n",
    "    out = open(parFile, 'w')\n",
    "    out.writelines(lines)\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['30', 'nx - grid cells in east/west direction\\n', 1]\n"
     ]
    }
   ],
   "source": [
    "#create dictionay with values from text file - may want to use for calibration\n",
    "def getparams(file_name):\n",
    "    myvars = {}\n",
    "    lines = open(file_name, 'r').readlines()\n",
    "    for i in range(len(lines)):\n",
    "        line=lines[i]\n",
    "        var, name = line.partition(\"!\")[::2]\n",
    "        #create a dictionary with the variable name as the key for the \n",
    "        #[model value, parFile text, linenumber]\n",
    "        myvars[name.split()[0]] = [var.strip(),name,i+1]\n",
    "    return myvars\n",
    "base = getparams(parFile)\n",
    "#print(base)\n",
    "print(base['nx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "edit_par(base,'enbal_output_fname','new/path/file.gdat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#likely a way to do this with a dictionary \n",
    "def edit_par(par_dict,parameter,new_value):\n",
    "    lines = open(parFile, 'r').readlines()\n",
    "    if par_dict[parameter][2] == 14 or par_dict[parameter][2] == 17 \\\n",
    "    or par_dict[parameter][2] == 18 or par_dict[parameter][2] == 19 \\\n",
    "    or par_dict[parameter][2] == 93 or par_dict[parameter][2] == 95 \\\n",
    "    or par_dict[parameter][2] == 97 or par_dict[parameter][2] == 100 \\\n",
    "    or par_dict[parameter][2] == 102 or par_dict[parameter][2] == 104 \\\n",
    "    or par_dict[parameter][2] == 107 or par_dict[parameter][2] == 108:\n",
    "        text = str(new_value)+'\\n'\n",
    "    else:\n",
    "        text = str(new_value)+'\\t\\t\\t!'+par_dict[parameter][1]\n",
    "    lines[par_dict[parameter][2]] = text\n",
    "    out = open(parFile, 'w')\n",
    "    out.writelines(lines)\n",
    "    out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:snowmodelcal]",
   "language": "python",
   "name": "conda-env-snowmodelcal-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
